---
title: Load balancing
permalink: load-balancing
categories:
- program
tags: 
- server
comments: true
date: 2019-09-18
updated: 2019-09-18
---


## 介绍

负载均衡，是现代计算机领域的基础服务之一。其基本原理是通过运行在前面的负载均衡服务，按照指定的负载均衡算法，将流量分配到后端服务集群上，从而为系统提供横向扩展的能力。以此来分散压力的一种架构方式。

负载均衡服务一般都会有内外网隔离、健康检查等功能，从而提高系统的安全性和可用性。

## Key Words

- 负载均衡器

  将用户访问的请求，根据负载均衡算法，分发到集群中的一台处理服务器。

- Load balancing ： 负载均衡

- 集群（Cluster）

  将同一应用部署到多台机器上，组成处理集群，接收负载均衡设备分发的请求，进行处理，并返回相应数据。

- OSI

- 纵向扩展 （Scale Up）

- 横向扩展 （Scale Out） 

## 场景

系统的扩展可分为纵向（垂直）扩展和横向（水平）扩展。纵向扩展，是从单机的角度通过增加硬件处理能力，比如CPU处理能力，内存容量，磁盘等方面，实现服务器处理能力的提升，不能满足大型分布式系统（网站），大流量，高并发，海量数据的问题。因此需要采用横向扩展的方式，通过添加机器来满足大型网站服务的处理能力。比如：一台机器不能满足，则增加两台或者多台机器，共同承担访问压力。这就是典型的集群和负载均衡架构

### 没有负载均衡的 web 架构

![](https://spaco.oss-cn-hangzhou.aliyuncs.com/load-balancing/no-load-balancing.jpg)

在这里用户是直连到 web 服务器，如果这个服务器宕机了，那么用户自然也就没办法访问了。另外，如果同时有很多用户试图访问服务器，超过了其能处理的极限，就会出现加载速度缓慢或根本无法连接的情况。

### 使用负载均衡的 web 架构

而通过在后端引入一个负载均衡器和至少一个额外的 web 服务器，可以缓解这个故障。通常情况下，所有的后端服务器会保证提供相同的内容，以便用户无论哪个服务器响应，都能收到一致的内容。

![](https://spaco.oss-cn-hangzhou.aliyuncs.com/load-balancing/load-balancing.jpg)

从图里可以看到，用户访问负载均衡器，再由负载均衡器将请求转发给后端服务器。在这种情况下，单点故障现在转移到负载均衡器上了。这里又可以通过引入负载均衡器集群来缓解。

### 负载均衡器集群

![](https://spaco.oss-cn-hangzhou.aliyuncs.com/load-balancing/load-balancing-cluster.jpg)

## 优点

- 流量分发 : 提高应用处理性能（增加吞吐量，加强网络处理能力）

  这个是负载均衡服务的核心功能，作为统一的流量入口，负载均衡服务会把流量分发到后端的多个节点上，从而实现集群的横向扩展。当需要扩容时，只需要在负载均衡服务后面加入新的节点就可以了，而不用改变入口。

- 系统高可用 : 故障转移

  通过加入后端多个节点，可以显著地提高服务的可用性。而且负载均衡服务一般会集成健康检查功能，在后端节点出现异常时会把请求转发到健康的节点上去，从而实现异常的自动处理。

- 在线扩容/缩容 : 提供网站伸缩性（扩展性) 

  高峰扩容，低峰缩容

## 负载均衡器可以处理什么样的请求？

负载均衡器的管理员能主要为下面四种主要类型的请求设置转发规则：

- HTTP
- HTTPS
- TCP
- UDP

## 负载均衡器如何选择要转发的后端服务器？

负载均衡器一般根据两个因素来决定要将请求转发到哪个服务器。首先，确保所选择的服务器能够对请求做出响应，然后根据预先配置的规则从健康服务器池（healthy pool）中进行选择。

因为，负载均衡器应当只选择能正常做出响应的后端服务器，因此就需要有一种判断后端服务器是否「健康」的方法。为了监视后台服务器的运行状况，运行状态检查服务会定期尝试使用转发规则定义的协议和端口去连接后端服务器。如果，服务器无法通过健康检查，就会从池中剔除，保证流量不会被转发到该服务器，直到其再次通过健康检查为止。

## 原理与实现

任何的负载均衡技术都要想办法建立某种一对多的映射机制：一个请求的入口映射到多个处理请求的节点，从而实现分而治之（Divide and Conquer）。
这种映射机制使得多个物理存在对外体现为一个虚拟的整体，对服务的请求者屏蔽了内部的结构。
采用不同的机制建立映射关系，可以形成不同的负载均衡技术，常见的包括：

- DNS轮询
- CDN
- IP负载均衡

### DNS轮询

[协议层】DNS域名解析负载均衡 

原理：**在DNS服务器上配置多个域名对应IP的记录**。例如一个域名www.baidu.com对应一组web服务器IP地址，域名解析时经过DNS服务器的算法将一个域名请求分配到合适的真实服务器上。 

DNS轮询是最简单的负载均衡方式。以域名作为访问入口，通过配置多条DNS A记录使得请求可以分配到不同的服务器。
DNS轮询没有快速的健康检查机制，而且只支持WRR的调度策略导致负载很难“均衡”，通常用于要求不高的场景。并且DNS轮询方式直接将服务器的真实地址暴露给用户，不利于服务器安全。

### CDN

CDN（Content Delivery Network，内容分发网络）。通过发布机制将内容同步到大量的缓存节点，并在DNS服务器上进行扩展，找到里用户最近的缓存节点作为服务提供节点。
因为很难自建大量的缓存节点，所以通常使用CDN运营商的服务。目前国内的服务商很少，而且按流量计费，价格也比较昂贵。

### IP负载均衡

IP负载均衡是基于特定的TCP/IP技术实现的负载均衡。

IP负载均衡可以使用硬件设备，也可以使用软件实现。硬件设备的主要产品是F5-BIG-IP-GTM（简称F5)，`软件产品主要有LVS、HAProxy、NginX`。其中LVS、HAProxy可以工作在4-7层，NginX工作在7层。关于三者的简单对比，可以参考[这里](http://localhost:4000/2012/10/16/weblayer_nginx_keepalived.html#2.3 负载均衡器选型-ref)。

硬件负载均衡设备可以将核心部分做成芯片，性能和稳定性更好，而且商用产品的可管理性、文档和服务都比较好。

软件负载均衡通常是开源软件。自由度较高，但学习成本和管理成本会比较大。

## 实现



## 实现方式

- http重定向

- DNS负载均衡

- 反向代理负载均衡

- IP负载均衡(LVS-NAT)

- 直接路由(LVS-DR)

- IP 隧道


## 常用案例

- NginX + keepalive
- Spring Cloud Ribbon
- Kong
- Dubbo

## 注意点

- 健康检查

## 负载均衡算法

更详细的负载均衡算法请参考[这里]()

### Round Robin （轮询）

### Weighted Round Robin （加权轮询）

### Random（随机）

### Hash （哈希）

### Least Connection （最小连接数）

### Least Response Time（最短响应时间）

### IP Hash（Source Hash）

### 

## 常用

- Round Robin （轮询）
- Weighted Round Robin （加权轮询）

## 引用

- [Web负载均衡的几种实现方式](https://blog.csdn.net/zhoudaxia/article/details/23672319)
- [https://zhuanlan.zhihu.com/p/61776638](https://zhuanlan.zhihu.com/p/61776638)